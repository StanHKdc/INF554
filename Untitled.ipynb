{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1960f550",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np \n",
    "from torch_geometric.data import Data\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F \n",
    "from torch_geometric.nn import GCNConv, TopKPooling, global_mean_pool\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.transforms import NormalizeFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "3701929a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2000, 0.2000, 0.2000])\n"
     ]
    }
   ],
   "source": [
    "x=torch.tensor([[0.1,0.1,0.1],[0.2,0.2,0.2],[0.3,0.3,0.3],[0.1,0.1,0.1],[0.4,0.4,0.4]])\n",
    "# X c'est les features des noeuds : une table de features = un noeud, il faut mettre les features des auteurs ici en \n",
    "# connaissant l'équivalent indices/auteurs pour pouvoir les retrouver \n",
    "# Exemple : [0.2,0.2,0.2] correspond au 2ème auteur et les valeurs sont ses features \n",
    "print(x[1])\n",
    "\n",
    "y=torch.tensor([0.1,0.2,0.3,0.1,0])\n",
    "# Correspond aux valeurs recherchées : il faut en mettre POUR TOUT LES AUTEURS MEME LES PAS CONNUS (de ce que j'ai vu ça influence pas)\n",
    "\n",
    "\n",
    "train_mask=torch.tensor([True,True,True,True,False])\n",
    "# Correspond à la table des h connus ou non (sur lesquels on va s'entrainer) ce qu'on peut faire \n",
    "# c'est (pour vérifier que ça marche) mettre true sur 80% du train et false sur 20% \n",
    "# et on test sur les 20% qu'on connait pas déjà mais dont on a les solutions pour vérifier\n",
    "\n",
    "test_mask=torch.tensor([False,False,False,False,True])\n",
    "# Opposé de train (les valeurs sur lesquelles on veut faire le test)\n",
    "\n",
    "edge_index=torch.tensor([[0,0,0,0,1,1,1,1,2,2,2,2,3,3,3,3,4,4,4,4],[1,2,3,4,0,2,3,4,0,1,3,4,0,1,2,4,0,1,2,3]])\n",
    "\n",
    "# Table de taille [2,nombre de liens] qui representent TOUT les liens entre les noeuds (il faut les foutre dans les deux sens)\n",
    "#Genre  (0,1) et (1,0) c'est pas pareil\n",
    "\n",
    "\n",
    "testset=Data(x=x,y=y,edge_index=edge_index,classes=1,test_mask=test_mask,train_mask=train_mask)\n",
    "\n",
    "#definition de la table data\n",
    "\n",
    "classes=1  # On dit qu'il y a qu'une classe à chercher (le h ici)\n",
    "num_features=testset.num_features  #Donne le nombre de features pour chaque noeud\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b53317a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): GCNConv(3, 16)\n",
      "  (conv2): GCNConv(16, 16)\n",
      "  (conv3): GCNConv(16, 16)\n",
      "  (out): Linear(in_features=16, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv #GATConv\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(42)\n",
    "\n",
    "        # Initialize the layers\n",
    "        self.conv1 = GCNConv(num_features, hidden_channels) # Entrée du réseau : taille  features to hidden\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)   # Autre niveau hiddent to hidden\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)   # On fait 3 niveau ici mais on peut en rajouter tjr celon le même schéma\n",
    "        self.out = Linear(hidden_channels, classes)     # Sortie du résau : hidden to taille de la classe, ici 1 \n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # First Message Passing Layer (Transformation)\n",
    "        x = self.conv1(x, edge_index)  \n",
    "        x=F.tanh(x)\n",
    "        #x = x.relu()   J'ai changé la fonction à voir si certaines marchent mieux que d'autres \n",
    "       # x = F.dropout(x, p=0.5, training=self.training)  On peut laisser ça pour essayer ou non, dans mon exemple j'avais pas assez de donnés pour le tej\n",
    "\n",
    "        # Second Message Passing Layer\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x=F.tanh(x)\n",
    "        #x = x.relu() #Autre fonction à tester ici \n",
    "        #x = F.dropout(x, p=0.5, training=self.training)\n",
    "        \n",
    "        x = self.conv3(x, edge_index)\n",
    "        x=F.tanh(x)\n",
    "        #x = x.relu()\n",
    "        #x = F.dropout(x, p=0.5, training=self.training)\n",
    "\n",
    "        # Output layer \n",
    "        x = self.out(x) #Peut rajouter autre chose ici \n",
    "        return x\n",
    "\n",
    "model = GCN(hidden_channels=16) #On peut changer la tailles des embedings ici (surtout dans notre cas ce sera plus grand je pense)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "bb6b9b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gregl\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:520: UserWarning: Using a target size (torch.Size([4])) that is different to the input size (torch.Size([4, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.2689\n",
      "Epoch: 100, Loss: 0.0829\n",
      "Epoch: 200, Loss: 0.0829\n",
      "Epoch: 300, Loss: 0.0829\n",
      "Epoch: 400, Loss: 0.0829\n",
      "Epoch: 500, Loss: 0.0829\n",
      "Epoch: 600, Loss: 0.0829\n",
      "Epoch: 700, Loss: 0.0829\n",
      "Epoch: 800, Loss: 0.0829\n",
      "Epoch: 900, Loss: 0.0829\n",
      "Epoch: 1000, Loss: 0.0829\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "model = GCN(hidden_channels=16)  #Taille des embedings\n",
    "\n",
    "# Use GPU # \"cuda:0\" if torch.cuda.is_available() else on peut mettre cette commande devant le \"cpu\" dans le torch.device pour que ça tourne sur GPU mais moi ça marche pô\n",
    "device = torch.device(\"cpu\")\n",
    "model = model.to(device)\n",
    "testset = testset.to(device)\n",
    "\n",
    "# Initialize Optimizer\n",
    "learning_rate = 0.01\n",
    "decay = 5e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), \n",
    "                             lr=learning_rate, \n",
    "                             weight_decay=decay)\n",
    "loss_fn = torch.nn.MSELoss()    # On calcul la perte avec MSE \n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad() \n",
    "      # Use all data as input, because all nodes have node features\n",
    "    out = model(testset.x, testset.edge_index)  \n",
    "      # Only use nodes with labels available for loss calculation --> mask\n",
    "    loss = torch.sqrt(loss_fn(out[testset.train_mask], testset.y[testset.train_mask]))  \n",
    "    loss.backward() \n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    out = model(testset.x, testset.edge_index)\n",
    "    # Use the class with highest probability.\n",
    "    pred = out  \n",
    "    # Check against ground-truth labels.\n",
    "    test_correct = pred[testset.test_mask] == testset.y[testset.test_mask]  \n",
    "    print(pred[testset.test_mask])\n",
    "    print(testset.y[testset.test_mask] )\n",
    "    # Derive ratio of correct predictions.\n",
    "    test_acc = int(test_correct.sum()) / int(testset.test_mask.sum())  \n",
    "    return test_acc\n",
    "\n",
    "losses = []\n",
    "for epoch in range(0, 1001):\n",
    "    loss = train()\n",
    "    losses.append(loss)\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "76a841a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gregl\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "losses_float = [float(loss.cpu().detach().numpy()) for loss in losses] \n",
    "loss_indices = [i for i,l in enumerate(losses_float)] \n",
    "plt = sns.lineplot(loss_indices, losses_float)\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "83dd2a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1750]], grad_fn=<IndexBackward0>)\n",
      "tensor([0.])\n",
      "Test Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gregl\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    }
   ],
   "source": [
    "test_acc = test()\n",
    "print(f'Test Accuracy: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dc67ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": false,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
